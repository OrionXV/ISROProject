{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OrionXV/ISROProject/blob/main/plotfitterClassDocumented.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dependencies\n",
        "import astropy.convolution.convolve as conv\n",
        "from astropy.convolution import Box1DKernel as box1d\n",
        "from astropy.convolution import Gaussian1DKernel as g1d\n",
        "from astropy.table import Table\n",
        "import pandas as pd\n",
        "from matplotlib.pyplot import figure\n",
        "from scipy.signal import find_peaks\n",
        "from scipy.signal import peak_widths\n",
        "import math \n",
        "from scipy.optimize import curve_fit\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np \n",
        "from scipy.optimize import leastsq\n",
        "from scipy.special import erf\n",
        "%config InLineBackend.figure_format = 'retina'\n",
        "\n",
        "class Curve_Fitter():\n",
        "    #data_path to initialize the dataframe which we will work on. Only required parameter.\n",
        "    def __init__(self, data_path, convo_size = 60):\n",
        "        self.data_raw = Table.read(data_path).to_pandas()\n",
        "        self.data = self.convolve(self.data_raw, convo_size) #we will use convolved data for most of our purposes\n",
        "\n",
        "    #function to convovle the data, returns a new dataframe\n",
        "    def convolve(self, data, width):\n",
        "        data2 = data.copy()\n",
        "        data2['RATE'] = conv(np.array(data['RATE']), kernel = g1d(width), boundary = 'extend')\n",
        "        return data2\n",
        "    \n",
        "    #MATHS AHEAD\n",
        "    #Z = (2*B + (C**2)*D)/(2*C)\n",
        "    #Just a temp function so we don't have to write the expression again and again\n",
        "    def z_func(self, B, C, D):\n",
        "        return (2*B + (C**2)*D)/(2*C)\n",
        "    \n",
        "    #Our objective function, we will fit our curve over this\n",
        "    def objective_func(self, T, A, B, C, D, E, F):\n",
        "        return math.sqrt(np.pi*0.5)*A*C*np.exp(D/2*((2*B)+(C**2)*(D/2)-(2*(T*E+ F))))*(erf(self.z_func(B, C, D))- erf(self.z_func(B, C, D) - (T*E+ F)/C))\n",
        "\n",
        "    #Defining the cost function. We will use sqrt(chi) for our calculations   \n",
        "    def objective_cost_func(self, params, x, y):\n",
        "        a0, b0, c0, d0, e0, f0 = params[0], params[1], params[2], params[3], params[4], params[5]\n",
        "        return np.sqrt(((y - self.objective_func(x, a0, b0, c0, d0, e0, f0))**2)/y)\n",
        "\n",
        "    #Sclaing functions\n",
        "    def min_max_scaler(self, df):\n",
        "        df['RATESCALED'] = (df['RATE']- df['RATE'].min())/(df['RATE'].max()- df['RATE'].min())\n",
        "        df['TIMESCALED'] = (df['TIME']- df['TIME'].min())/(df['TIME'].max()- df['TIME'].min())*2\n",
        "\n",
        "    def rev_scaler(self, df, x):\n",
        "        return x*(df['RATE'].max()- df['RATE'].min()) + df['RATE'].min()\n",
        "    \n",
        "    #tolerence_func is a simple method to determine whether the range of the snippet we take for fitting does not exceed the bounds of our dataframe\n",
        "    def tolerence_func(self, r, mid, start, stop):\n",
        "        if mid - start < 0:\n",
        "            start = 0\n",
        "        else:\n",
        "            start = mid - start\n",
        "        if mid + stop > r:\n",
        "            stop = r\n",
        "        else:\n",
        "            stop = mid + stop\n",
        "        return start, stop\n",
        " \n",
        "    #Main function, it fits the data over our objective function. Returns a list of dictionaries that tell us about the peaks and how we have fitted over them.\n",
        "    #It also initializes the self.peak_df which is a data frame containing all the data for the peaks we have found\n",
        "    #By default it uses the convolved data\n",
        "\n",
        "    def peak_fitter(self, df = None, rel_height = 1):\n",
        "        df = self.data if df is None else df\n",
        "        peak_list, _ = find_peaks(df['RATE'], distance= df['RATE'].median()*1.10)\n",
        "        self.min_max_scaler(df)\n",
        "        #df['FIT'] = None\n",
        "        peak_data_list = []\n",
        "        peak_df_list = []\n",
        "        for peak in peak_list:\n",
        "            widths = peak_widths(df['RATE'], peak_list , rel_height = rel_height)\n",
        "            t1 = widths[2] + 200 #df['RATE'][peak]*3 #2.747; Arbitrary \n",
        "            t2 = widths[3] + 400 #t1*ratio \n",
        "            start, stop = self.tolerence_func(len(df), peak, int(t1), int(t2))\n",
        "            TIME = df['TIMESCALED'][start:stop] - df['TIMESCALED'][start] #Some scaling\n",
        "            RATE = df['RATESCALED'][start:stop]\n",
        "\n",
        "            params = [0.2, 0.3, 0.3, 0.4, 0.1, 0.1] #Rando params \n",
        "\n",
        "            resultsq = leastsq(self.objective_cost_func, params, (TIME, RATE))\n",
        "            a, b, c, d, e, f = resultsq[0][0], resultsq[0][1], resultsq[0][2], resultsq[0][3], resultsq[0][4], resultsq[0][5]\n",
        "\n",
        "\n",
        "            new_curve = self.objective_func(TIME, a, b, c, d, e, f)\n",
        "            #Our dicc\n",
        "            peak_dic = {\n",
        "                'start' : start,\n",
        "                'stop' : stop,\n",
        "                'rate_curve' : new_curve,\n",
        "                'rate_curve_scaled' : self.rev_scaler(df, new_curve),\n",
        "                'curve_params' : [a, b, c, d, e, f],\n",
        "                'fitted_on' : (TIME, RATE)\n",
        "            }\n",
        "            peak_df_list.append(pd.DataFrame.from_dic(peak_dic)) #For the dataframe \n",
        "            peak_data_list.append(peak_dic) #For the list\n",
        "\n",
        "        self.peak_df = pd.concat(peak_df_list)\n",
        "        self.peak_dic_list = peak_data_list\n",
        "        return peak_data_list\n",
        "    \n",
        "    #Plots our data, if you have already called fitter, then pass the params in here. \n",
        "    def peak_data_plotter(self, df = None, peak_list = None):\n",
        "        df = self.data if df is None else df\n",
        "        peak_list = self.peak_fitter() if peak_list is None else peak_list\n",
        "        figure(figsize=(20, 8), dpi=80)\n",
        "        plt.plot(df['TIME'], df['RATE'])\n",
        "        for peak in peak_list:\n",
        "            plt.plot(df['TIME'][peak.get('start', 0):peak.get('stop', 0)], peak.get('rate_curve_scaled'))"
      ],
      "metadata": {
        "id": "I27b8pLNKkAd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "N16aBhZBnYcm"
      },
      "execution_count": 1,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "plotfitter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNewQPyXiMSJsAcCaJ++k4I",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}